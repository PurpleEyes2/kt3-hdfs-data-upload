{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3263d2e6",
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [],
   "source": [
    "# Импорт библиотек\n",
    "import os\n",
    "import zipfile\n",
    "from pathlib import Path\n",
    "from datetime import datetime\n",
    "import pandas as pd\n",
    "from kaggle.api.kaggle_api_extended import KaggleApi"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4c4b9ba6",
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [],
   "source": [
    "# Настройка путей\n",
    "BASE_DIR = Path.cwd().parent\n",
    "DATA_RAW = BASE_DIR / 'data' / 'raw'\n",
    "DATA_PROCESSED = BASE_DIR / 'data' / 'processed'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e7d572e2",
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [],
   "source": [
    "# Создание директорий\n",
    "DATA_RAW.mkdir(parents=True, exist_ok=True)\n",
    "DATA_PROCESSED.mkdir(parents=True, exist_ok=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a3200e69",
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [],
   "source": [
    "def download_kaggle_dataset(dataset, path):\n",
    "    \"\"\"Скачать датасет с Kaggle\"\"\"\n",
    "    from kaggle.api.kaggle_api_extended import KaggleApi\n",
    "    \n",
    "    api = KaggleApi()\n",
    "    api.authenticate()\n",
    "    \n",
    "    # Разделение на владельца и название\n",
    "    owner, dataset_name = dataset.split('/')\n",
    "    \n",
    "    # Скачивание\n",
    "    api.dataset_download_files(dataset, path=path, unzip=False)\n",
    "    \n",
    "    return path / f\"{dataset_name}.zip\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fdc18a17",
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [],
   "source": [
    "# Скачивание датасетов\n",
    "world_events_zip = download_kaggle_dataset(\n",
    "    'saketk511/world-important-events-ancient-to-modern',\n",
    "    DATA_RAW / 'world_events'\n",
    ")\n",
    "\n",
    "car_accident_zip = download_kaggle_dataset(\n",
    "    'nextmillionaire/car-accident-dataset',\n",
    "    DATA_RAW / 'car_accident'\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a8fbe0c0",
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [],
   "source": [
    "def extract_zip(zip_path, extract_to):\n",
    "    \"\"\"Распаковать архив\"\"\"\n",
    "    with zipfile.ZipFile(zip_path, 'r') as zip_ref:\n",
    "        zip_ref.extractall(extract_to)\n",
    "    return extract_to\n",
    "\n",
    "# Распаковка\n",
    "world_events_dir = extract_zip(world_events_zip, DATA_RAW / 'world_events')\n",
    "car_accident_dir = extract_zip(car_accident_zip, DATA_RAW / 'car_accident')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9cee8305",
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [],
   "source": [
    "def normalize_data(df):\n",
    "    \"\"\"Нормализация данных\"\"\"\n",
    "    # Приведение названий колонок\n",
    "    df.columns = (\n",
    "        df.columns\n",
    "        .str.strip()\n",
    "        .str.lower()\n",
    "        .str.replace(r'[\\s\\-\\.]+', '_', regex=True)\n",
    "        .str.replace(r'[^a-z0-9_]', '', regex=True)\n",
    "        .str.strip('_')\n",
    "    )\n",
    "    \n",
    "    # Конвертация дат\n",
    "    for col in df.columns:\n",
    "        if 'date' in col or 'time' in col:\n",
    "            try:\n",
    "                df[col] = pd.to_datetime(df[col]).dt.strftime('%Y-%m-%d')\n",
    "            except:\n",
    "                continue\n",
    "    \n",
    "    # Очистка\n",
    "    df = df.replace(r'^\\s*$', None, regex=True)\n",
    "    df = df.drop_duplicates()\n",
    "    \n",
    "    return df\n",
    "\n",
    "# Обработка исторических событий\n",
    "world_events = pd.read_csv(next(world_events_dir.glob('*.csv')))\n",
    "world_events = normalize_data(world_events)\n",
    "world_events.to_parquet(\n",
    "    DATA_PROCESSED / 'world_events.parquet',\n",
    "    engine='pyarrow',\n",
    "    compression='snappy'\n",
    ")\n",
    "\n",
    "# Обработка данных об авариях\n",
    "car_accident = pd.read_csv(next(car_accident_dir.glob('*.csv')))\n",
    "car_accident = normalize_data(car_accident)\n",
    "car_accident.to_parquet(\n",
    "    DATA_PROCESSED / 'car_accident.parquet',\n",
    "    engine='pyarrow',\n",
    "    compression='snappy'\n",
    ")"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
