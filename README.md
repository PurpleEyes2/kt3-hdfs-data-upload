# Отчет по проекту: Пайплайн обработки данных для HDFS

## Оглавление
1. [Описание проекта](#описание-проекта)
2. [Структура проекта](#структура-проекта)
3. [Требования](#требования)
4. [Установка и настройка](#установка-и-настройка)
5. [Выполнение работы](#выполнение-работы)
6. [Результаты](#результаты)
7. [Заключение](#заключение)

## Описание проекта
Проект реализует ETL-пайплайн для:
- Загрузки датасетов с Kaggle
- Очистки и нормализации данных
- Конвертации в формат Parquet
- Загрузки в HDFS

## Структура проекта
.
├── data/ # Данные (исключены из git)
│ ├── raw/ # Исходные данные
│ └── processed/ # Обработанные данные
├── scripts/
│ ├── normalize.ipynb # Ноутбук обработки
│ └── upload_to_hdfs.py # Скрипт загрузки
├── docs/ # Документация
├── docker-compose.yml # Конфигурация Hadoop
├── requirements.txt # Зависимости Python
└── README.md # Этот файл


## Требования
- Python 3.8+
- Docker
- Kaggle API key
- 4GB свободной памяти

## Установка и настройка

### 1. Подготовка окружения
